{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "que = '오늘날씨는어떻게되나요?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘날씨는'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(question):\n",
    "    if '날씨' and '기온' in question :\n",
    "        return '오늘날씨는더워요'\n",
    "    else :\n",
    "        return '무슨 말인지 모르겠습니다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'무슨 말인지 모르겠습니다'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('오늘날씨는')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'무슨 말인지 모르겠습니다'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('오늘날이어때')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘날씨는더워요'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('오늘날씨와기온은')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(question):\n",
    "    if '날씨' in question :\n",
    "        return '오늘날씨는더워요'\n",
    "    elif '기온' in question :\n",
    "        return '오늘 날씨는 맑고 기온은 10도 입니다.'\n",
    "    else :\n",
    "        return '무슨 말인지 모르겠습니다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘 날씨는 맑고 기온은 10도 입니다.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('오늘 기온')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['날씨','기온','온도', 'weather', '비', '우산', '구름']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(question):\n",
    "    for word in words:\n",
    "        if word in question:\n",
    "            return '오늘 날씨는 맑고 기온은 10도입니다.'\n",
    "    return '무슨말인지 모르겠습니다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'무슨말인지 모르겠습니다'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('우박')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘 날씨는 맑고 기온은 10도입니다.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('how is the weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def chatbot3(question):\n",
    "    w=pd.read_csv('날씨키워드.csv', engine='python', encoding='euc-kr')\n",
    "    for word in w.values:\n",
    "        if word[0] in question:\n",
    "            return '오늘 날씨는 너무 덥습니다'\n",
    "        \n",
    "    return '다시말해주세요'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['고기', '온도']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.nouns('고기온도가 어때?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오늘', '축구']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.nouns('오늘 축구 비겼어?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(question):\n",
    "    w = pd.read_csv('날씨키워드.csv', engine='python', encoding ='euc-kr')\n",
    "    nouns = tagger.nouns(question)\n",
    "    for word in w.values:\n",
    "        if word[0] in nouns:\n",
    "            return '오늘 날씨는 맑고 기온은 10도입니다'\n",
    "    return '무슨 말인지 모르겠습니다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=re.compile(r'((?P<place>.+)날씨)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['서울']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=r.match('서울의 날씨는 어때')\n",
    "group = m.groupdict()\n",
    "place = group['place']\n",
    "tagger.nouns(place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_place(question):\n",
    "    r=re.compile(r'((?P<place>.+)날씨)')\n",
    "    m=r.match(question)\n",
    "    group=m.groupdict()\n",
    "    date=group['place']\n",
    "    return tagger.nouns(place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['서울']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_place('서울의 날씨 알려줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['서울']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_place('제주도 날씨 어때')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=re.compile(r'((?P<date>\\S+) )?((?P<place>\\S+) )?날씨')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = r.match('내일은 서울의 날씨가 어떨까?').groupdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '내일은', 'place': '서울의'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_place(question):\n",
    "    r=re.compile(r'((?P<date>\\S+) )?((?P<place>\\S+) )?날씨')\n",
    "    m= r.match(question).groupdict()\n",
    "    \n",
    "    if m['date']:\n",
    "        m['date'] = tagger.nouns(m['date'])\n",
    "    if m['place']:\n",
    "        m['place'] = tagger.nouns(m['place'])\n",
    "        \n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': ['내일'], 'place': ['서울']}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_date_place('내일은 서울의 날씨가 어때')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_date ={'오늘':'오늘은 전국적으로 비가 내릴 것으로 예상합니다', '내일':'내일은 맑습니다'}\n",
    "w_place = {'서울': '서울의 최고기온은 30도 입니다.', '제주도':'제주도의 최고 기온은 28도 입니다'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': ['오늘'], 'place': ['서울']}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = get_date_place('오늘 서울의 날씨는 어때?')\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘은 전국적으로 비가 내릴 것으로 예상합니다 서울의 최고기온은 30도 입니다.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_date[answer['date'][0]] +' '+w_place[answer['place'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_place(question):\n",
    "    r=re.compile(r'((?P<date>\\S+) )?((?P<place>\\S+) )?날씨')\n",
    "    m= r.match(question)\n",
    "    \n",
    "    if m:\n",
    "        m = m.groupdict()\n",
    "        \n",
    "        if m['date']:\n",
    "            date = tagger.nouns(m['date'])\n",
    "            segment = w_date[date[0]]\n",
    "\n",
    "        if m['place']:\n",
    "            place = tagger.nouns(m['place'])\n",
    "            segment2 = w_place[place[0]]\n",
    "            \n",
    "        segment = segment + '\\n' + segment2\n",
    "    else :\n",
    "        segment = '무슨말인지 모르겠습니다'\n",
    "    return segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘은 전국적으로 비가 내릴 것으로 예상합니다\\n서울의 최고기온은 30도 입니다.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_date_place('오늘 서울의 날씨는 어때')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arg = ['오늘', '오늘은','내일', '내일은']\n",
    "data_pred = ['날씨?','날씨는?','날씨어때?','날씨가 어때?']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for arg in data_arg:\n",
    "    for pred in data_pred:\n",
    "        sentence = arg+' '+ pred\n",
    "        data.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오늘 날씨?',\n",
       " '오늘 날씨는?',\n",
       " '오늘 날씨어때?',\n",
       " '오늘 날씨가 어때?',\n",
       " '오늘은 날씨?',\n",
       " '오늘은 날씨는?',\n",
       " '오늘은 날씨어때?',\n",
       " '오늘은 날씨가 어때?',\n",
       " '내일 날씨?',\n",
       " '내일 날씨는?',\n",
       " '내일 날씨어때?',\n",
       " '내일 날씨가 어때?',\n",
       " '내일은 날씨?',\n",
       " '내일은 날씨는?',\n",
       " '내일은 날씨어때?',\n",
       " '내일은 날씨가 어때?']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAXLEN = max(len(s) for s in data)\n",
    "MAXLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1,\n",
       " '날': 2,\n",
       " '씨': 3,\n",
       " '?': 4,\n",
       " '오': 5,\n",
       " '늘': 6,\n",
       " '어': 7,\n",
       " '때': 8,\n",
       " '은': 9,\n",
       " '내': 10,\n",
       " '일': 11,\n",
       " '는': 12,\n",
       " '가': 13}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = Tokenizer(char_level=True)\n",
    "tok.fit_on_texts(data)\n",
    "tok.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 6, 1, 2, 3, 4],\n",
       " [5, 6, 1, 2, 3, 12, 4],\n",
       " [5, 6, 1, 2, 3, 7, 8, 4],\n",
       " [5, 6, 1, 2, 3, 13, 1, 7, 8, 4],\n",
       " [5, 6, 9, 1, 2, 3, 4],\n",
       " [5, 6, 9, 1, 2, 3, 12, 4],\n",
       " [5, 6, 9, 1, 2, 3, 7, 8, 4],\n",
       " [5, 6, 9, 1, 2, 3, 13, 1, 7, 8, 4],\n",
       " [10, 11, 1, 2, 3, 4],\n",
       " [10, 11, 1, 2, 3, 12, 4],\n",
       " [10, 11, 1, 2, 3, 7, 8, 4],\n",
       " [10, 11, 1, 2, 3, 13, 1, 7, 8, 4],\n",
       " [10, 11, 9, 1, 2, 3, 4],\n",
       " [10, 11, 9, 1, 2, 3, 12, 4],\n",
       " [10, 11, 9, 1, 2, 3, 7, 8, 4],\n",
       " [10, 11, 9, 1, 2, 3, 13, 1, 7, 8, 4]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tok.texts_to_sequences(data)\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  6,  1,  2,  3,  4,  0,  0,  0,  0,  0],\n",
       "       [ 5,  6,  1,  2,  3, 12,  4,  0,  0,  0,  0],\n",
       "       [ 5,  6,  1,  2,  3,  7,  8,  4,  0,  0,  0],\n",
       "       [ 5,  6,  1,  2,  3, 13,  1,  7,  8,  4,  0],\n",
       "       [ 5,  6,  9,  1,  2,  3,  4,  0,  0,  0,  0],\n",
       "       [ 5,  6,  9,  1,  2,  3, 12,  4,  0,  0,  0],\n",
       "       [ 5,  6,  9,  1,  2,  3,  7,  8,  4,  0,  0],\n",
       "       [ 5,  6,  9,  1,  2,  3, 13,  1,  7,  8,  4],\n",
       "       [10, 11,  1,  2,  3,  4,  0,  0,  0,  0,  0],\n",
       "       [10, 11,  1,  2,  3, 12,  4,  0,  0,  0,  0],\n",
       "       [10, 11,  1,  2,  3,  7,  8,  4,  0,  0,  0],\n",
       "       [10, 11,  1,  2,  3, 13,  1,  7,  8,  4,  0],\n",
       "       [10, 11,  9,  1,  2,  3,  4,  0,  0,  0,  0],\n",
       "       [10, 11,  9,  1,  2,  3, 12,  4,  0,  0,  0],\n",
       "       [10, 11,  9,  1,  2,  3,  7,  8,  4,  0,  0],\n",
       "       [10, 11,  9,  1,  2,  3, 13,  1,  7,  8,  4]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = pad_sequences(sequence, padding='post')\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for s in data : \n",
    "    labels.append([1, 2] + [0 for _ in s [2:]])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오</td>\n",
       "      <td>늘</td>\n",
       "      <td>은</td>\n",
       "      <td></td>\n",
       "      <td>날</td>\n",
       "      <td>씨</td>\n",
       "      <td>어</td>\n",
       "      <td>때</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8\n",
       "0  1  2  0  0  0  0  0  0  0\n",
       "1  오  늘  은     날  씨  어  때  ?"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([labels[6], list(data[6])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_sequences(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 11)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 11, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y.reshape((16,11,1))\n",
    "y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CHAR = len(tok.word_index)+1\n",
    "NUM_CHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.layers import concatenate, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 11, 2)             28        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 11, 2)             40        \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 11, 3)             9         \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(NUM_CHAR, 2, input_length=MAXLEN))\n",
    "model1.add(LSTM(2, return_sequences=True))\n",
    "model1.add(TimeDistributed(Dense(3, activation = 'softmax')))\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 11, 2)             28        \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 11, 2)             40        \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 11, 3)             9         \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(NUM_CHAR, 2, input_length=MAXLEN))\n",
    "model2.add(LSTM(2, return_sequences=True, go_backwards=True))\n",
    "model2.add(TimeDistributed(Dense(3, activation = 'softmax')))\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 11, 2)        28          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 11, 2)        40          embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 11, 2)        40          embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 11, 4)        0           lstm_8[0][0]                     \n",
      "                                                                 lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 11, 3)        15          concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 123\n",
      "Trainable params: 123\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_input = Input(shape=(MAXLEN,),dtype = 'int32')\n",
    "layer_embed=Embedding(NUM_CHAR, 2, input_length=MAXLEN)(layer_input)\n",
    "layer_forward  = LSTM(2, return_sequences=True)(layer_embed)\n",
    "layer_backward = LSTM(2, return_sequences=True, go_backwards = True)(layer_embed)\n",
    "merged = concatenate([layer_forward, layer_backward])\n",
    "\n",
    "outputs = TimeDistributed(Dense(3, activation='softmax'))(merged)\n",
    "model3 = Model(layer_input, outputs)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 16:02:34.527491 11428 deprecation_wrapper.py:119] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0814 16:02:34.541412 11428 deprecation_wrapper.py:119] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer='RMSprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model2.compile(optimizer='RMSprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model3.compile(optimizer='RMSprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 16:02:37.271567 11428 deprecation.py:323] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0814 16:02:37.680329 11428 deprecation_wrapper.py:119] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 1.0737 - acc: 0.7955\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0334 - acc: 0.8182\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9957 - acc: 0.8182\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9569 - acc: 0.8182\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9172 - acc: 0.8182\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8771 - acc: 0.8182\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8374 - acc: 0.8182\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7997 - acc: 0.8182\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7645 - acc: 0.8182\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7326 - acc: 0.8182\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7041 - acc: 0.8182\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6795 - acc: 0.8182\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6589 - acc: 0.8182\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6421 - acc: 0.8182\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6289 - acc: 0.8182\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6186 - acc: 0.8182\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6111 - acc: 0.8182\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6057 - acc: 0.8182\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6016 - acc: 0.8182\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5983 - acc: 0.8182\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5956 - acc: 0.8182\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5929 - acc: 0.8182\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5905 - acc: 0.8182\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5880 - acc: 0.8182\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5857 - acc: 0.8182\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5833 - acc: 0.8182\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5810 - acc: 0.8182\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5787 - acc: 0.8182\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5764 - acc: 0.8182\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5741 - acc: 0.8182\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5719 - acc: 0.8182\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5697 - acc: 0.8182\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5675 - acc: 0.8182\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5654 - acc: 0.8182\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5633 - acc: 0.8182\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5613 - acc: 0.8182\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5592 - acc: 0.8182\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5572 - acc: 0.8182\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5552 - acc: 0.8182\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5534 - acc: 0.8182\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5515 - acc: 0.8182\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5496 - acc: 0.8182\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5479 - acc: 0.8182\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5461 - acc: 0.8182\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5444 - acc: 0.8182\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5426 - acc: 0.8182\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5410 - acc: 0.8182\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5394 - acc: 0.8182\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5379 - acc: 0.8182\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5363 - acc: 0.8182\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5347 - acc: 0.8182\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5334 - acc: 0.8182\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5321 - acc: 0.8182\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5305 - acc: 0.8182\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5293 - acc: 0.8182\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5280 - acc: 0.8182\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5268 - acc: 0.8182\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5257 - acc: 0.8182\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5246 - acc: 0.8182\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5234 - acc: 0.8182\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5224 - acc: 0.8182\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5213 - acc: 0.8182\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5204 - acc: 0.8182\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5194 - acc: 0.8182\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5185 - acc: 0.8182\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5175 - acc: 0.8182\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5168 - acc: 0.8182\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5158 - acc: 0.8182\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5151 - acc: 0.8182\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5143 - acc: 0.8182\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5135 - acc: 0.8182\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5128 - acc: 0.8182\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5119 - acc: 0.8182\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5113 - acc: 0.8182\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5108 - acc: 0.8182\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5101 - acc: 0.8182\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5094 - acc: 0.8182\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5090 - acc: 0.8182\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5082 - acc: 0.8182\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5077 - acc: 0.8182\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5071 - acc: 0.8182\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5066 - acc: 0.8182\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5062 - acc: 0.8182\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5056 - acc: 0.8182\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5050 - acc: 0.8182\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5045 - acc: 0.8182\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5041 - acc: 0.8182\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5037 - acc: 0.8182\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5031 - acc: 0.8182\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5027 - acc: 0.8182\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5022 - acc: 0.8182\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5018 - acc: 0.8182\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5013 - acc: 0.8182\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5010 - acc: 0.8182\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5005 - acc: 0.8182\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5000 - acc: 0.8182\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4997 - acc: 0.8182\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4992 - acc: 0.8182\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4989 - acc: 0.8182\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4986 - acc: 0.8182\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4981 - acc: 0.8182\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4977 - acc: 0.8182\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4974 - acc: 0.8182\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4969 - acc: 0.8182\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4966 - acc: 0.8182\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4961 - acc: 0.8182\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4957 - acc: 0.8182\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4955 - acc: 0.8182\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4950 - acc: 0.8182\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4948 - acc: 0.8182\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4943 - acc: 0.8182\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4939 - acc: 0.8182\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4936 - acc: 0.8182\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4932 - acc: 0.8182\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4928 - acc: 0.8182\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4926 - acc: 0.8182\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4921 - acc: 0.8182\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4917 - acc: 0.8182\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4916 - acc: 0.8182\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4911 - acc: 0.8182\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4908 - acc: 0.8182\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4902 - acc: 0.8182\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4899 - acc: 0.8182\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4897 - acc: 0.8182\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4892 - acc: 0.8182\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4889 - acc: 0.8182\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4884 - acc: 0.8182\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4879 - acc: 0.8182\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4878 - acc: 0.8182\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4873 - acc: 0.8182\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4868 - acc: 0.8182\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4866 - acc: 0.8182\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4860 - acc: 0.8182\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4857 - acc: 0.8182\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4854 - acc: 0.8182\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4849 - acc: 0.8182\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4845 - acc: 0.8182\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4843 - acc: 0.8182\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4838 - acc: 0.8182\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4835 - acc: 0.8182\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4833 - acc: 0.8182\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4827 - acc: 0.8182\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4824 - acc: 0.8182\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4818 - acc: 0.8182\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4817 - acc: 0.8182\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4812 - acc: 0.8182\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4811 - acc: 0.8182\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4806 - acc: 0.8182\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4805 - acc: 0.8182\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4799 - acc: 0.8182\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4796 - acc: 0.8182\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4790 - acc: 0.8182\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4788 - acc: 0.8182\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4785 - acc: 0.8182\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4783 - acc: 0.8182\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4780 - acc: 0.8182\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4776 - acc: 0.8182\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4774 - acc: 0.8182\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4772 - acc: 0.8182\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4768 - acc: 0.8182\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4765 - acc: 0.8182\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4761 - acc: 0.8182\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4762 - acc: 0.8182\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4755 - acc: 0.8182\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4757 - acc: 0.8182\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4752 - acc: 0.8182\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4750 - acc: 0.8182\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4748 - acc: 0.8182\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4744 - acc: 0.8182\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4745 - acc: 0.8182\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4741 - acc: 0.8182\n",
      "Epoch 172/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4740 - acc: 0.8182\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4737 - acc: 0.8182\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4736 - acc: 0.8182\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4734 - acc: 0.8182\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4732 - acc: 0.8182\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4731 - acc: 0.8182\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4728 - acc: 0.8182\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4728 - acc: 0.8182\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4727 - acc: 0.8182\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4723 - acc: 0.8182\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4718 - acc: 0.8182\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4723 - acc: 0.8182\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4719 - acc: 0.8182\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4720 - acc: 0.8182\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4716 - acc: 0.8182\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4717 - acc: 0.8182\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4712 - acc: 0.8182\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4712 - acc: 0.8182\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4703 - acc: 0.8182\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4709 - acc: 0.8182\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4712 - acc: 0.8182\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4708 - acc: 0.8182\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4694 - acc: 0.8182\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4713 - acc: 0.8182\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4704 - acc: 0.8182\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4707 - acc: 0.8182\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4697 - acc: 0.8182\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4699 - acc: 0.8182\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4699 - acc: 0.8182\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4701 - acc: 0.8182\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4697 - acc: 0.8182\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4695 - acc: 0.8182\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4695 - acc: 0.8182\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4694 - acc: 0.8182\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4693 - acc: 0.8182\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4689 - acc: 0.8182\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4693 - acc: 0.8182\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4687 - acc: 0.8182\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4688 - acc: 0.8182\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4681 - acc: 0.8182\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4693 - acc: 0.8182\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4685 - acc: 0.8182\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4685 - acc: 0.8182\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4678 - acc: 0.8182\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4684 - acc: 0.8182\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4683 - acc: 0.8182\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4677 - acc: 0.8182\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4679 - acc: 0.8182\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4680 - acc: 0.8182\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4679 - acc: 0.8182\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4677 - acc: 0.8182\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4676 - acc: 0.8182\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4671 - acc: 0.8182\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4676 - acc: 0.8182\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4663 - acc: 0.8182\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4676 - acc: 0.8182\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4676 - acc: 0.8182\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4666 - acc: 0.8182\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4672 - acc: 0.8182\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4666 - acc: 0.8182\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4668 - acc: 0.8182\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4668 - acc: 0.8182\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4663 - acc: 0.8182\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4668 - acc: 0.8182\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4664 - acc: 0.8182\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4668 - acc: 0.8182\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4655 - acc: 0.8182\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4662 - acc: 0.8182\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4665 - acc: 0.8182\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4656 - acc: 0.8182\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4654 - acc: 0.8182\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4661 - acc: 0.8182\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4659 - acc: 0.8182\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4646 - acc: 0.8182\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4660 - acc: 0.8182\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4641 - acc: 0.8182\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4660 - acc: 0.8182\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4657 - acc: 0.8182\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4650 - acc: 0.8182\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4656 - acc: 0.8182\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4654 - acc: 0.8182\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4647 - acc: 0.8182\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4646 - acc: 0.8182\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4655 - acc: 0.8182\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4646 - acc: 0.8182\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4651 - acc: 0.8182\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4639 - acc: 0.8182\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4657 - acc: 0.8182\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4645 - acc: 0.8182\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4646 - acc: 0.8182\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4634 - acc: 0.8182\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4649 - acc: 0.8182\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4633 - acc: 0.8182\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4652 - acc: 0.8182\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4644 - acc: 0.8182\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4639 - acc: 0.8182\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4643 - acc: 0.8182\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4644 - acc: 0.8182\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4640 - acc: 0.8182\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4635 - acc: 0.8182\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4640 - acc: 0.8182\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4633 - acc: 0.8182\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4635 - acc: 0.8182\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4634 - acc: 0.8182\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4646 - acc: 0.8182\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4627 - acc: 0.8182\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4636 - acc: 0.8182\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4633 - acc: 0.8182\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4634 - acc: 0.8182\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4641 - acc: 0.8182\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4632 - acc: 0.8182\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4635 - acc: 0.8182\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4631 - acc: 0.8182\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4626 - acc: 0.8182\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4629 - acc: 0.8182\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4635 - acc: 0.8182\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4624 - acc: 0.8182\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4628 - acc: 0.8182\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4635 - acc: 0.8182\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4627 - acc: 0.8182\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4630 - acc: 0.8182\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4618 - acc: 0.8182\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4634 - acc: 0.8182\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4628 - acc: 0.8182\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4630 - acc: 0.8182\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4629 - acc: 0.8182\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4618 - acc: 0.8182\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4613 - acc: 0.8182\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4628 - acc: 0.8182\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 1.0723 - acc: 0.8182\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0358 - acc: 0.8182\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0003 - acc: 0.8182\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9625 - acc: 0.8182\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9221 - acc: 0.8182\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8803 - acc: 0.8182\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8381 - acc: 0.8182\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7976 - acc: 0.8182\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7596 - acc: 0.8182\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7252 - acc: 0.8182\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6947 - acc: 0.8182\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6676 - acc: 0.8182\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6448 - acc: 0.8182\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6252 - acc: 0.8182\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6091 - acc: 0.8182\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5957 - acc: 0.8182\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5843 - acc: 0.8182\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5748 - acc: 0.8182\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5666 - acc: 0.8182\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5592 - acc: 0.8182\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5521 - acc: 0.8182\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5452 - acc: 0.8182\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5382 - acc: 0.8182\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5307 - acc: 0.8182\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5229 - acc: 0.8182\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5146 - acc: 0.8182\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5059 - acc: 0.8182\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4970 - acc: 0.8182\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4881 - acc: 0.8182\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4790 - acc: 0.8182\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4702 - acc: 0.8182\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4617 - acc: 0.8182\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4531 - acc: 0.8182\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4449 - acc: 0.8182\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4369 - acc: 0.8182\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4292 - acc: 0.8182\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4217 - acc: 0.8182\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4144 - acc: 0.8182\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4071 - acc: 0.8182\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3997 - acc: 0.8182\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3924 - acc: 0.8182\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3850 - acc: 0.8182\n",
      "Epoch 43/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3776 - acc: 0.8182\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3699 - acc: 0.8182\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3624 - acc: 0.8182\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3550 - acc: 0.8182\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3474 - acc: 0.8182\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3398 - acc: 0.8182\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3323 - acc: 0.8182\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3245 - acc: 0.8182\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3170 - acc: 0.8182\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3095 - acc: 0.8182\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3019 - acc: 0.8182\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2948 - acc: 0.8239\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2877 - acc: 0.8295\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2807 - acc: 0.8466\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2741 - acc: 0.8693\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2676 - acc: 0.8864\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2612 - acc: 0.9034\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2547 - acc: 0.9091\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2487 - acc: 0.9091\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2431 - acc: 0.9091\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2378 - acc: 0.9091\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2329 - acc: 0.9148\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2281 - acc: 0.9205\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2235 - acc: 0.9318\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2191 - acc: 0.9375\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2148 - acc: 0.9432\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2106 - acc: 0.9432\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2064 - acc: 0.9432\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2024 - acc: 0.9432\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1985 - acc: 0.9432\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1946 - acc: 0.9432\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1908 - acc: 0.9545\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1870 - acc: 0.9545\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1833 - acc: 0.9659\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1797 - acc: 0.9659\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1760 - acc: 0.9773\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1724 - acc: 0.9830\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1688 - acc: 0.9943\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1653 - acc: 1.0000\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1619 - acc: 1.0000\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1584 - acc: 1.0000\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1550 - acc: 1.0000\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1518 - acc: 1.0000\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1486 - acc: 1.0000\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1455 - acc: 1.0000\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1424 - acc: 1.0000\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1393 - acc: 1.0000\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1362 - acc: 1.0000\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1332 - acc: 1.0000\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1303 - acc: 1.0000\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1274 - acc: 1.0000\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1246 - acc: 1.0000\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1218 - acc: 1.0000\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1190 - acc: 1.0000\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1163 - acc: 1.0000\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1136 - acc: 1.0000\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1111 - acc: 1.0000\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1085 - acc: 1.0000\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1060 - acc: 1.0000\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1036 - acc: 1.0000\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1012 - acc: 1.0000\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0988 - acc: 1.0000\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0966 - acc: 1.0000\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0945 - acc: 1.0000\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0924 - acc: 1.0000\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0904 - acc: 1.0000\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0885 - acc: 1.0000\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0865 - acc: 1.0000\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0848 - acc: 1.0000\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0831 - acc: 1.0000\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0816 - acc: 1.0000\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0800 - acc: 1.0000\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0784 - acc: 1.0000\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0768 - acc: 1.0000\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0753 - acc: 1.0000\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0737 - acc: 1.0000\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0723 - acc: 1.0000\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0708 - acc: 1.0000\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0693 - acc: 1.0000\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0678 - acc: 1.0000\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0664 - acc: 1.0000\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0650 - acc: 1.0000\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0636 - acc: 1.0000\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0622 - acc: 1.0000\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0609 - acc: 1.0000\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0595 - acc: 1.0000\n",
      "Epoch 129/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0582 - acc: 1.0000\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0569 - acc: 1.0000\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0556 - acc: 1.0000\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0543 - acc: 1.0000\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0530 - acc: 1.0000\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0517 - acc: 1.0000\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0493 - acc: 1.0000\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0481 - acc: 1.0000\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0458 - acc: 1.0000\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0446 - acc: 1.0000\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0435 - acc: 1.0000\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0438 - acc: 1.000 - 0s 5ms/step - loss: 0.0424 - acc: 1.0000\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0403 - acc: 1.0000\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0392 - acc: 1.0000\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0382 - acc: 1.0000\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0363 - acc: 1.0000\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0353 - acc: 1.0000\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0335 - acc: 1.0000\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0326 - acc: 1.0000\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0317 - acc: 1.0000\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0231 - acc: 1.0000\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0118 - acc: 1.0000\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 214/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0031 - acc: 1.000 - 0s 5ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 299/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 1.0731 - acc: 0.7500\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0302 - acc: 0.8182\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9869 - acc: 0.8182\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9396 - acc: 0.8182\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.8887 - acc: 0.8182\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.8367 - acc: 0.8182\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7854 - acc: 0.8182\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7378 - acc: 0.8182\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6962 - acc: 0.8182\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6605 - acc: 0.8182\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6329 - acc: 0.8182\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6130 - acc: 0.8182\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5991 - acc: 0.8182\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5907 - acc: 0.8182\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5853 - acc: 0.8182\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5814 - acc: 0.8182\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5780 - acc: 0.8182\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5749 - acc: 0.8182\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5717 - acc: 0.8182\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5683 - acc: 0.8182\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5647 - acc: 0.8182\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5611 - acc: 0.8182\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5574 - acc: 0.8182\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5535 - acc: 0.8182\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5493 - acc: 0.8182\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5448 - acc: 0.8182\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5404 - acc: 0.8182\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5357 - acc: 0.8182\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5309 - acc: 0.8182\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5257 - acc: 0.8182\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5205 - acc: 0.8182\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5152 - acc: 0.8182\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5098 - acc: 0.8182\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5044 - acc: 0.8182\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4988 - acc: 0.8182\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4934 - acc: 0.8182\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4877 - acc: 0.8182\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4822 - acc: 0.8182\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4766 - acc: 0.8182\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4710 - acc: 0.8182\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4655 - acc: 0.8182\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4598 - acc: 0.8182\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4541 - acc: 0.8182\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4484 - acc: 0.8182\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4425 - acc: 0.8182\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4365 - acc: 0.8182\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4303 - acc: 0.8182\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4244 - acc: 0.8182\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4183 - acc: 0.8182\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4121 - acc: 0.8182\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4059 - acc: 0.8182\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3998 - acc: 0.8182\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3935 - acc: 0.8182\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3872 - acc: 0.8182\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3809 - acc: 0.8182\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3746 - acc: 0.8182\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3682 - acc: 0.8182\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3619 - acc: 0.8182\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3555 - acc: 0.8182\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3490 - acc: 0.8182\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3427 - acc: 0.8239\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3362 - acc: 0.8466\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3300 - acc: 0.8523\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3231 - acc: 0.8636\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3170 - acc: 0.8636\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3105 - acc: 0.8636\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3042 - acc: 0.8750\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2981 - acc: 0.8750\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2919 - acc: 0.8807\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2855 - acc: 0.8864\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2795 - acc: 0.8864\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2736 - acc: 0.8977\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2677 - acc: 0.9091\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2616 - acc: 0.9205\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2556 - acc: 0.9205\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2500 - acc: 0.9205\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2442 - acc: 0.9205\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2390 - acc: 0.9318\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2333 - acc: 0.9432\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2282 - acc: 0.9432\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2230 - acc: 0.9432\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2178 - acc: 0.9602\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2133 - acc: 0.9659\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2091 - acc: 0.9659\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2047 - acc: 0.9659\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2007 - acc: 0.9659\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1965 - acc: 0.9659\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1920 - acc: 0.9659\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1891 - acc: 0.9773\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1850 - acc: 0.9773\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1813 - acc: 0.9773\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1776 - acc: 0.9773\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1742 - acc: 0.9773\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1708 - acc: 0.9773\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1671 - acc: 0.9773\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1638 - acc: 0.9773\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1604 - acc: 0.9773\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1572 - acc: 0.9773\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1540 - acc: 0.9773\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1509 - acc: 0.9773\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1476 - acc: 0.9773\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1447 - acc: 0.9773\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1417 - acc: 0.9773\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1388 - acc: 0.9773\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1357 - acc: 0.9830\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1332 - acc: 0.9773\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1303 - acc: 0.9773\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1275 - acc: 0.9830\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1248 - acc: 0.9886\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1221 - acc: 0.9886\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1196 - acc: 0.9886\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1168 - acc: 0.9886\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1143 - acc: 0.9886\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1116 - acc: 0.9886\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1092 - acc: 0.9886\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1068 - acc: 0.9886\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1045 - acc: 0.9886\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1021 - acc: 0.9886\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1000 - acc: 0.9886\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0978 - acc: 0.9886\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0956 - acc: 0.9886\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0935 - acc: 0.9886\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0916 - acc: 0.9886\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0894 - acc: 0.9886\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0874 - acc: 0.9886\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0855 - acc: 0.9886\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0836 - acc: 0.9886\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0816 - acc: 0.9886\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0798 - acc: 0.9886\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0779 - acc: 0.9943\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0762 - acc: 0.9886\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0744 - acc: 0.9943\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0727 - acc: 1.0000\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0710 - acc: 1.0000\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0694 - acc: 1.0000\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0677 - acc: 1.0000\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0663 - acc: 1.0000\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0648 - acc: 1.0000\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0633 - acc: 1.0000\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0619 - acc: 1.0000\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0606 - acc: 1.0000\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0592 - acc: 1.0000\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0579 - acc: 1.0000\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0566 - acc: 1.0000\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0553 - acc: 1.0000\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0541 - acc: 1.0000\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0529 - acc: 1.0000\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0518 - acc: 1.0000\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0506 - acc: 1.0000\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0495 - acc: 1.0000\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0484 - acc: 1.0000\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0473 - acc: 1.0000\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0463 - acc: 1.0000\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0452 - acc: 1.0000\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0442 - acc: 1.0000\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0431 - acc: 1.0000\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0422 - acc: 1.0000\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0402 - acc: 1.0000\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0393 - acc: 1.0000\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0383 - acc: 1.0000\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0375 - acc: 1.0000\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0315 - acc: 1.0000\n",
      "Epoch 170/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0307 - acc: 1.0000\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 1.0000\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0203 - acc: 1.0000\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0106 - acc: 1.0000A: 0s - loss: 0.0109 - acc: 1.000\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 255/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0022 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(padded, y2, batch_size=1, epochs=300)\n",
    "history2= model2.fit(padded, y2, batch_size=1, epochs=300)\n",
    "history3 = model3.fit(padded, y2, batch_size=1, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history3.history['acc'])\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['Forward', 'Backward', 'Bi-direction'], loc='lower right');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[8.58353734e-01, 7.53795058e-02, 6.62666932e-02],\n",
       "        [7.22950161e-01, 1.40799373e-01, 1.36250570e-01],\n",
       "        [5.79467356e-01, 2.06472933e-01, 2.14059681e-01],\n",
       "        [4.79713053e-01, 2.50521004e-01, 2.69765943e-01],\n",
       "        [3.86459053e-01, 2.89722860e-01, 3.23818028e-01],\n",
       "        [3.54810715e-01, 3.04236978e-01, 3.40952307e-01],\n",
       "        [4.87192035e-01, 2.49999568e-01, 2.62808383e-01],\n",
       "        [7.71027803e-01, 1.19201787e-01, 1.09770440e-01],\n",
       "        [9.74665761e-01, 1.48622459e-02, 1.04720201e-02],\n",
       "        [9.97609854e-01, 1.56170188e-03, 8.28475982e-04],\n",
       "        [9.98874009e-01, 7.58425507e-04, 3.67569097e-04]],\n",
       "\n",
       "       [[8.58353734e-01, 7.53795058e-02, 6.62666932e-02],\n",
       "        [7.22950161e-01, 1.40799373e-01, 1.36250570e-01],\n",
       "        [5.79467356e-01, 2.06472933e-01, 2.14059681e-01],\n",
       "        [4.79713053e-01, 2.50521004e-01, 2.69765943e-01],\n",
       "        [3.86459053e-01, 2.89722860e-01, 3.23818028e-01],\n",
       "        [5.40382624e-01, 2.26196364e-01, 2.33421028e-01],\n",
       "        [6.55194759e-01, 1.74280897e-01, 1.70524344e-01],\n",
       "        [9.32566702e-01, 3.76718566e-02, 2.97614783e-02],\n",
       "        [9.95359004e-01, 2.94833700e-03, 1.69259345e-03],\n",
       "        [9.98691857e-01, 8.76023376e-04, 4.32220375e-04],\n",
       "        [9.98994052e-01, 6.80607918e-04, 3.25410685e-04]],\n",
       "\n",
       "       [[8.58353734e-01, 7.53795058e-02, 6.62666932e-02],\n",
       "        [7.22950161e-01, 1.40799373e-01, 1.36250570e-01],\n",
       "        [5.79467356e-01, 2.06472933e-01, 2.14059681e-01],\n",
       "        [4.79713053e-01, 2.50521004e-01, 2.69765943e-01],\n",
       "        [3.86459053e-01, 2.89722860e-01, 3.23818028e-01],\n",
       "        [9.90272939e-01, 6.01812545e-03, 3.70883383e-03],\n",
       "        [9.98609662e-01, 9.29785252e-04, 4.60544717e-04],\n",
       "        [9.98973966e-01, 6.93809940e-04, 3.32214171e-04],\n",
       "        [9.99033928e-01, 6.54699514e-04, 3.11467244e-04],\n",
       "        [9.99043047e-01, 6.48659421e-04, 3.08274699e-04],\n",
       "        [9.99044478e-01, 6.47707726e-04, 3.07771930e-04]],\n",
       "\n",
       "       [[8.58353734e-01, 7.53795058e-02, 6.62666932e-02],\n",
       "        [7.22950161e-01, 1.40799373e-01, 1.36250570e-01],\n",
       "        [5.79467356e-01, 2.06472933e-01, 2.14059681e-01],\n",
       "        [4.79713053e-01, 2.50521004e-01, 2.69765943e-01],\n",
       "        [3.86459053e-01, 2.89722860e-01, 3.23818028e-01],\n",
       "        [9.88391042e-01, 7.10706552e-03, 4.50184755e-03],\n",
       "        [9.90999401e-01, 5.57012018e-03, 3.43039678e-03],\n",
       "        [9.98814821e-01, 7.97076325e-04, 3.88145330e-04],\n",
       "        [9.99016047e-01, 6.66310487e-04, 3.17671947e-04],\n",
       "        [9.99039710e-01, 6.50888076e-04, 3.09457188e-04],\n",
       "        [9.99043882e-01, 6.48059533e-04, 3.07958777e-04]],\n",
       "\n",
       "       [[8.58353734e-01, 7.53795058e-02, 6.62666932e-02],\n",
       "        [7.22950161e-01, 1.40799373e-01, 1.36250570e-01],\n",
       "        [7.99672842e-01, 1.04861893e-01, 9.54653472e-02],\n",
       "        [6.75371468e-01, 1.63560078e-01, 1.61068410e-01],\n",
       "        [6.35110199e-01, 1.82322010e-01, 1.82567790e-01],\n",
       "        [6.09394312e-01, 1.93997785e-01, 1.96607843e-01],\n",
       "        [7.47627020e-01, 1.30297914e-01, 1.22075029e-01],\n",
       "        [9.69670415e-01, 1.76212173e-02, 1.27084255e-02],\n",
       "        [9.97358859e-01, 1.71797723e-03, 9.23107029e-04],\n",
       "        [9.98850465e-01, 7.73604552e-04, 3.75915697e-04],\n",
       "        [9.99015689e-01, 6.66468171e-04, 3.17830621e-04]],\n",
       "\n",
       "       [[8.58353734e-01, 7.53795058e-02, 6.62666932e-02],\n",
       "        [7.22950161e-01, 1.40799373e-01, 1.36250570e-01],\n",
       "        [7.99672842e-01, 1.04861893e-01, 9.54653472e-02],\n",
       "        [6.75371468e-01, 1.63560078e-01, 1.61068410e-01],\n",
       "        [6.35110199e-01, 1.82322010e-01, 1.82567790e-01],\n",
       "        [6.09394312e-01, 1.93997785e-01, 1.96607843e-01],\n",
       "        [9.12773550e-01, 4.79986295e-02, 3.92278470e-02],\n",
       "        [9.88048077e-01, 7.27036828e-03, 4.68162959e-03],\n",
       "        [9.98324931e-01, 1.11111277e-03, 5.63977170e-04],\n",
       "        [9.98948872e-01, 7.09969376e-04, 3.41163919e-04],\n",
       "        [9.99029994e-01, 6.57144352e-04, 3.12810327e-04]],\n",
       "\n",
       "       [[8.58353734e-01, 7.53795058e-02, 6.62666932e-02],\n",
       "        [7.22950161e-01, 1.40799373e-01, 1.36250570e-01],\n",
       "        [7.99672842e-01, 1.04861893e-01, 9.54653472e-02],\n",
       "        [6.75371468e-01, 1.63560078e-01, 1.61068410e-01],\n",
       "        [6.35110199e-01, 1.82322010e-01, 1.82567790e-01],\n",
       "        [6.09394312e-01, 1.93997785e-01, 1.96607843e-01],\n",
       "        [9.95369852e-01, 2.95151421e-03, 1.67866889e-03],\n",
       "        [9.98785675e-01, 8.15915759e-04, 3.98379110e-04],\n",
       "        [9.99001086e-01, 6.76070340e-04, 3.22826090e-04],\n",
       "        [9.99037981e-01, 6.51985931e-04, 3.10038304e-04],\n",
       "        [9.99043643e-01, 6.48232759e-04, 3.08050076e-04]],\n",
       "\n",
       "       [[8.58353734e-01, 7.53795058e-02, 6.62666932e-02],\n",
       "        [7.22950161e-01, 1.40799373e-01, 1.36250570e-01],\n",
       "        [7.99672842e-01, 1.04861893e-01, 9.54653472e-02],\n",
       "        [6.75371468e-01, 1.63560078e-01, 1.61068410e-01],\n",
       "        [6.35110199e-01, 1.82322010e-01, 1.82567790e-01],\n",
       "        [6.09394312e-01, 1.93997785e-01, 1.96607843e-01],\n",
       "        [9.95187879e-01, 3.06249131e-03, 1.74965733e-03],\n",
       "        [9.96742904e-01, 2.11180048e-03, 1.14534295e-03],\n",
       "        [9.98943388e-01, 7.13771326e-04, 3.42883635e-04],\n",
       "        [9.99031544e-01, 6.56196033e-04, 3.12261487e-04],\n",
       "        [9.99042451e-01, 6.49092195e-04, 3.08501243e-04]],\n",
       "\n",
       "       [[8.60227406e-01, 7.44123310e-02, 6.53602257e-02],\n",
       "        [7.21981406e-01, 1.41102150e-01, 1.36916459e-01],\n",
       "        [5.78298688e-01, 2.06851780e-01, 2.14849502e-01],\n",
       "        [4.77660507e-01, 2.51255482e-01, 2.71084040e-01],\n",
       "        [3.83764833e-01, 2.90699601e-01, 3.25535536e-01],\n",
       "        [3.50210071e-01, 3.05963188e-01, 3.43826741e-01],\n",
       "        [4.76505846e-01, 2.54563540e-01, 2.68930584e-01],\n",
       "        [7.54866719e-01, 1.27021685e-01, 1.18111588e-01],\n",
       "        [9.70665514e-01, 1.70826539e-02, 1.22518856e-02],\n",
       "        [9.97412503e-01, 1.68498862e-03, 9.02609725e-04],\n",
       "        [9.98855472e-01, 7.70434795e-04, 3.74137890e-04]],\n",
       "\n",
       "       [[8.60227406e-01, 7.44123310e-02, 6.53602257e-02],\n",
       "        [7.21981406e-01, 1.41102150e-01, 1.36916459e-01],\n",
       "        [5.78298688e-01, 2.06851780e-01, 2.14849502e-01],\n",
       "        [4.77660507e-01, 2.51255482e-01, 2.71084040e-01],\n",
       "        [3.83764833e-01, 2.90699601e-01, 3.25535536e-01],\n",
       "        [5.33075213e-01, 2.29339272e-01, 2.37585515e-01],\n",
       "        [6.43661976e-01, 1.79589912e-01, 1.76748082e-01],\n",
       "        [9.25713897e-01, 4.12829183e-02, 3.30032818e-02],\n",
       "        [9.94928956e-01, 3.20896646e-03, 1.86205690e-03],\n",
       "        [9.98661876e-01, 8.95258272e-04, 4.42918565e-04],\n",
       "        [9.98989999e-01, 6.83161081e-04, 3.26785492e-04]],\n",
       "\n",
       "       [[8.60227406e-01, 7.44123310e-02, 6.53602257e-02],\n",
       "        [7.21981406e-01, 1.41102150e-01, 1.36916459e-01],\n",
       "        [5.78298688e-01, 2.06851780e-01, 2.14849502e-01],\n",
       "        [4.77660507e-01, 2.51255482e-01, 2.71084040e-01],\n",
       "        [3.83764833e-01, 2.90699601e-01, 3.25535536e-01],\n",
       "        [9.90158141e-01, 6.08477229e-03, 3.75713734e-03],\n",
       "        [9.98606622e-01, 9.31715243e-04, 4.61664429e-04],\n",
       "        [9.98973608e-01, 6.94089278e-04, 3.32370255e-04],\n",
       "        [9.99033689e-01, 6.54742180e-04, 3.11490963e-04],\n",
       "        [9.99042928e-01, 6.48666115e-04, 3.08278482e-04],\n",
       "        [9.99044478e-01, 6.47708948e-04, 3.07772541e-04]],\n",
       "\n",
       "       [[8.60227406e-01, 7.44123310e-02, 6.53602257e-02],\n",
       "        [7.21981406e-01, 1.41102150e-01, 1.36916459e-01],\n",
       "        [5.78298688e-01, 2.06851780e-01, 2.14849502e-01],\n",
       "        [4.77660507e-01, 2.51255482e-01, 2.71084040e-01],\n",
       "        [3.83764833e-01, 2.90699601e-01, 3.25535536e-01],\n",
       "        [9.88213539e-01, 7.20870541e-03, 4.57777688e-03],\n",
       "        [9.90822196e-01, 5.67404414e-03, 3.50376102e-03],\n",
       "        [9.98811483e-01, 7.99123431e-04, 3.89291963e-04],\n",
       "        [9.99015570e-01, 6.66549138e-04, 3.17803002e-04],\n",
       "        [9.99039471e-01, 6.50929462e-04, 3.09479539e-04],\n",
       "        [9.99043882e-01, 6.48066343e-04, 3.07962007e-04]],\n",
       "\n",
       "       [[8.60227406e-01, 7.44123310e-02, 6.53602257e-02],\n",
       "        [7.21981406e-01, 1.41102150e-01, 1.36916459e-01],\n",
       "        [7.98070669e-01, 1.05551071e-01, 9.63782296e-02],\n",
       "        [6.72308207e-01, 1.64895847e-01, 1.62795916e-01],\n",
       "        [6.29583657e-01, 1.84769973e-01, 1.85646325e-01],\n",
       "        [6.00211382e-01, 1.98091999e-01, 2.01696604e-01],\n",
       "        [7.32685447e-01, 1.37425631e-01, 1.29888907e-01],\n",
       "        [9.65162456e-01, 2.00966485e-02, 1.47408899e-02],\n",
       "        [9.97129977e-01, 1.86019694e-03, 1.00987474e-03],\n",
       "        [9.98830020e-01, 7.86850811e-04, 3.83191102e-04],\n",
       "        [9.99012828e-01, 6.68354100e-04, 3.18846432e-04]],\n",
       "\n",
       "       [[8.60227406e-01, 7.44123310e-02, 6.53602257e-02],\n",
       "        [7.21981406e-01, 1.41102150e-01, 1.36916459e-01],\n",
       "        [7.98070669e-01, 1.05551071e-01, 9.63782296e-02],\n",
       "        [6.72308207e-01, 1.64895847e-01, 1.62795916e-01],\n",
       "        [6.29583657e-01, 1.84769973e-01, 1.85646325e-01],\n",
       "        [6.00211382e-01, 1.98091999e-01, 2.01696604e-01],\n",
       "        [9.05469298e-01, 5.17774150e-02, 4.27533239e-02],\n",
       "        [9.86280084e-01, 8.29123147e-03, 5.42871887e-03],\n",
       "        [9.98244643e-01, 1.16205611e-03, 5.93280827e-04],\n",
       "        [9.98939693e-01, 7.15892820e-04, 3.44380329e-04],\n",
       "        [9.99028683e-01, 6.58031553e-04, 3.13287310e-04]],\n",
       "\n",
       "       [[8.60227406e-01, 7.44123310e-02, 6.53602257e-02],\n",
       "        [7.21981406e-01, 1.41102150e-01, 1.36916459e-01],\n",
       "        [7.98070669e-01, 1.05551071e-01, 9.63782296e-02],\n",
       "        [6.72308207e-01, 1.64895847e-01, 1.62795916e-01],\n",
       "        [6.29583657e-01, 1.84769973e-01, 1.85646325e-01],\n",
       "        [6.00211382e-01, 1.98091999e-01, 2.01696604e-01],\n",
       "        [9.95255649e-01, 3.02105560e-03, 1.72334386e-03],\n",
       "        [9.98780668e-01, 8.19180044e-04, 4.00173623e-04],\n",
       "        [9.99000371e-01, 6.76589145e-04, 3.23103653e-04],\n",
       "        [9.99037862e-01, 6.52066024e-04, 3.10081436e-04],\n",
       "        [9.99043643e-01, 6.48245448e-04, 3.08057119e-04]],\n",
       "\n",
       "       [[8.60227406e-01, 7.44123310e-02, 6.53602257e-02],\n",
       "        [7.21981406e-01, 1.41102150e-01, 1.36916459e-01],\n",
       "        [7.98070669e-01, 1.05551071e-01, 9.63782296e-02],\n",
       "        [6.72308207e-01, 1.64895847e-01, 1.62795916e-01],\n",
       "        [6.29583657e-01, 1.84769973e-01, 1.85646325e-01],\n",
       "        [6.00211382e-01, 1.98091999e-01, 2.01696604e-01],\n",
       "        [9.95054245e-01, 3.14353267e-03, 1.80217368e-03],\n",
       "        [9.96646941e-01, 2.17114226e-03, 1.18186686e-03],\n",
       "        [9.98940527e-01, 7.15628674e-04, 3.43889493e-04],\n",
       "        [9.99031186e-01, 6.56430493e-04, 3.12387390e-04],\n",
       "        [9.99042213e-01, 6.49133755e-04, 3.08523566e-04]]], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1.predict(padded)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pred.argmax(axis=2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-ba42290b1024>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpadded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'result'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
